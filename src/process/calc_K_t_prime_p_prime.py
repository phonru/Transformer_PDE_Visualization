import numpy as np
import os
import torch
import argparse
from tqdm import tqdm
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
    
"""
ç®€åŒ–Kå¼ é‡è®¡ç®—è„šæœ¬

åŸå§‹å…¬å¼ï¼š
K(t,p,d;t',p',d') = A_TT(p',t,t') * W^Ïƒ^T(t',p) * A_PP(t,p,p') * W^Ïƒ^S(t,p') * W_dd^1(d',d)
                   + I_TT(t,t') * A_PP(t,p,p') * W^Ïƒ^S(t,p') * W_dd^2(d',d)
                   + I_PP(p',p) * A_TT(p,t,t') * W^Ïƒ^T(t',p) * W_dd^3(d',d)
ç®€åŒ–ä¸º2ç»´å¼ é‡ï¼š
K_t_prime_p_prime: (t', p') - å¯¹åº”å›ºå®š(t,p,d,d')ä¸‹çš„æ ¸å‡½æ•°å€¼
"""

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="è®¡ç®—ç®€åŒ–çš„Kå¼ é‡ - å›ºå®š(t,p,d,d')è®©(t',p')å˜åŒ–")
    
    # è·¯å¾„é…ç½®
    parser.add_argument('--input-dir', type=str, 
                       default="data/processed/HS_p",
                       help='è¾“å…¥æ•°æ®ç›®å½•è·¯å¾„ (é»˜è®¤: %(default)s)')
    parser.add_argument('--output-dir', type=str, 
                       default="data/processed/K_simplified",
                       help='è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: %(default)s)')
    
    # æ•°æ®é›†æ ·æœ¬é€‰æ‹©
    parser.add_argument('--datasets', type=str, default='all',
                       help='è¦å¤„ç†çš„æ•°æ®é›†ï¼Œæ”¯æŒæ ¼å¼: "all", "0", "0,1,2", "0-2" (é»˜è®¤: %(default)s)')
    parser.add_argument('--samples', type=str, default='all',
                       help='è¦å¤„ç†çš„æ ·æœ¬ï¼Œæ”¯æŒæ ¼å¼: "all", "0", "0,1,2", "0-5" (é»˜è®¤: %(default)s)')
    
    # éšæœºç§å­é…ç½®
    parser.add_argument('--global-seed', type=int, default=3571,
                       help='å…¨å±€éšæœºç§å­ï¼Œè®¾ä¸º-1è¡¨ç¤ºå®Œå…¨éšæœº (é»˜è®¤: %(default)s)')
    
    # å›ºå®šç»´åº¦é…ç½®ï¼ˆè¿™äº›å°†è¢«å›ºå®šï¼Œä¸å˜åŒ–ï¼‰
    parser.add_argument('--d-fixed', type=int, default=None,
                       help='å›ºå®šç‰¹å¾ç»´åº¦dï¼ŒèŒƒå›´[0, d_model)ï¼Œé€šå¸¸640 (é»˜è®¤: éšæœºé€‰æ‹©)')
    parser.add_argument('--d-prime-fixed', type=int, default=None,
                       help='å›ºå®šç‰¹å¾ç»´åº¦d\'ï¼ŒèŒƒå›´[0, d_model)ï¼Œé€šå¸¸640 (é»˜è®¤: éšæœºé€‰æ‹©)')
    parser.add_argument('--t-fixed', type=int, default=None,
                       help='å›ºå®šæ—¶é—´ç´¢å¼•tï¼ŒèŒƒå›´[0, t)ï¼Œé€šå¸¸15 (é»˜è®¤: éšæœºé€‰æ‹©)')
    parser.add_argument('--p-fixed', type=int, default=None,
                       help='å›ºå®šç©ºé—´ç´¢å¼•pï¼ŒèŒƒå›´[0, p)ï¼Œé€šå¸¸100 (é»˜è®¤: éšæœºé€‰æ‹©)')

    # è¾“å‡ºè·¯å¾„é…ç½®
    parser.add_argument('--add-seed-suffix', action='store_true', default=False,
                       help='æ˜¯å¦åœ¨è¾“å‡ºç›®å½•åæ·»åŠ éšæœºç§å­åç¼€ (é»˜è®¤: False)')
    
    return parser.parse_args()

def compute_K_simplified(At, As, W_sigma_t, W_sigma_s, Wdd1, Wdd2, Wdd3, 
                         random_seed=None, d_fixed=None, d_prime_fixed=None, 
                         t_fixed=None, p_fixed=None):
    """
    ç®€åŒ–è®¡ç®—Kå¼ é‡ä¸º2ç»´å¼ é‡ï¼Œå›ºå®š(t,p,d,d')è®©(t',p')å˜åŒ–ï¼š
    K_t_prime_p_prime: (t', p') - å¯¹åº”å›ºå®š(t,p,d,d')ä¸‹çš„æ ¸å‡½æ•°å€¼
    
    Args:
        At, As, W_sigma_t, W_sigma_s, Wdd1, Wdd2, Wdd3: å¼ é‡æ•°æ®
        random_seed: éšæœºç§å­
        d_fixed: æŒ‡å®šçš„ç‰¹å¾ç»´åº¦ dï¼ŒNoneè¡¨ç¤ºéšæœºé€‰æ‹©
        d_prime_fixed: æŒ‡å®šçš„ç‰¹å¾ç»´åº¦ d'ï¼ŒNoneè¡¨ç¤ºéšæœºé€‰æ‹©
        t_fixed: æŒ‡å®šçš„æ—¶é—´ç´¢å¼• tï¼ŒNoneè¡¨ç¤ºéšæœºé€‰æ‹©
        p_fixed: æŒ‡å®šçš„ç©ºé—´ç´¢å¼• pï¼ŒNoneè¡¨ç¤ºéšæœºé€‰æ‹©
    
    åŸå…¬å¼ï¼š
    K(t,p,d;t',p',d') = A_TT(p',t,t') * W^Ïƒ^T(t',p) * A_PP(t,p,p') * W^Ïƒ^S(t,p') * W_dd^1(d',d)
                       + I_TT(t,t') * A_PP(t,p,p') * W^Ïƒ^S(t,p') * W_dd^2(d',d)
                       + I_PP(p',p) * A_TT(p,t,t') * W^Ïƒ^T(t',p) * W_dd^3(d',d)
    """
    # è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯é‡å¤æ€§
    if random_seed is not None:
        np.random.seed(random_seed)
    
    # è½¬æ¢ä¸ºtorchå¼ é‡
    At_torch = torch.from_numpy(At).float()  # (p, t, t) - æ³¨æ„ï¼šç°åœ¨A_TTæ˜¯3ç»´çš„
    As_torch = torch.from_numpy(As).float()  # (t, p, p) - æ³¨æ„ï¼šç°åœ¨A_PPæ˜¯3ç»´çš„
    
    # ä»W_sigma_tè·å–ç»´åº¦ä¿¡æ¯ï¼š(t, p)
    t_max, p_max = W_sigma_t.shape
    d_model = Wdd1.shape[0]  # ä»WddçŸ©é˜µè·å–d_modelç»´åº¦ï¼Œé€šå¸¸æ˜¯640
    
    # æƒé‡çŸ©é˜µè½¬ä¸ºtorch
    Wdd1_torch = torch.from_numpy(Wdd1).float()
    Wdd2_torch = torch.from_numpy(Wdd2).float()
    Wdd3_torch = torch.from_numpy(Wdd3).float()
    W_sigma_t_torch = torch.from_numpy(W_sigma_t).float()  # (t, p)
    W_sigma_s_torch = torch.from_numpy(W_sigma_s).float()  # (t, p)
    
    # é€‰æ‹©å›ºå®šçš„ç»´åº¦ç´¢å¼•ï¼šå¦‚æœæŒ‡å®šäº†å°±ç”¨æŒ‡å®šå€¼ï¼Œå¦åˆ™éšæœºé€‰æ‹©
    d_fixed_val = d_fixed if d_fixed is not None else np.random.randint(0, d_model)
    d_prime_fixed_val = d_prime_fixed if d_prime_fixed is not None else np.random.randint(0, d_model)
    t_fixed_val = t_fixed if t_fixed is not None else np.random.randint(0, t_max)
    p_fixed_val = p_fixed if p_fixed is not None else np.random.randint(0, p_max)
    
    # æ£€æŸ¥ç´¢å¼•æœ‰æ•ˆæ€§
    if not (0 <= d_fixed_val < d_model):
        raise ValueError(f"d_fixed_val={d_fixed_val} è¶…å‡ºèŒƒå›´ [0, {d_model})")
    if not (0 <= d_prime_fixed_val < d_model):
        raise ValueError(f"d_prime_fixed_val={d_prime_fixed_val} è¶…å‡ºèŒƒå›´ [0, {d_model})")
    if not (0 <= t_fixed_val < t_max):
        raise ValueError(f"t_fixed_val={t_fixed_val} è¶…å‡ºèŒƒå›´ [0, {t_max})")
    if not (0 <= p_fixed_val < p_max):
        raise ValueError(f"p_fixed_val={p_fixed_val} è¶…å‡ºèŒƒå›´ [0, {p_max})")
    
    print(f"    ä½¿ç”¨å›ºå®šç´¢å¼•: t={t_fixed_val}{'(fixed)' if t_fixed is not None else '(random)'}, " +
          f"p={p_fixed_val}{'(fixed)' if p_fixed is not None else '(random)'}, " +
          f"d={d_fixed_val}{'(fixed)' if d_fixed is not None else '(random)'}, " +
          f"d'={d_prime_fixed_val}{'(fixed)' if d_prime_fixed is not None else '(random)'}")
    
    # è®¡ç®—å›ºå®šç‰¹å¾ç»´åº¦ä¸‹çš„æƒé‡æ ‡é‡
    w1_scalar = Wdd1_torch[d_prime_fixed_val, d_fixed_val].item()  # æ ‡é‡
    w2_scalar = Wdd2_torch[d_prime_fixed_val, d_fixed_val].item()
    w3_scalar = Wdd3_torch[d_prime_fixed_val, d_fixed_val].item()
    
    # ===== è®¡ç®— K_t_prime_p_prime: (t', p') =====
    # å›ºå®š t=t_fixed_val, p=p_fixed_val, d=d_fixed_val, d'=d_prime_fixed_val
    # K(t,p,d;t',p',d') çš„å…¬å¼ç®€åŒ–ä¸ºå…³äº(t',p')çš„å‡½æ•°
    
    # Term 1: A_TT(p',t,t') * W^Ïƒ^T(t',p) * A_PP(t,p,p') * W^Ïƒ^S(t,p') * w1
    # ç®€åŒ–ä¸º: A_TT(p',t_fixed_val,t') * W^Ïƒ^T(t',p_fixed_val) * A_PP(t_fixed_val,p_fixed_val,p') * W^Ïƒ^S(t_fixed_val,p') * w1
    # éœ€è¦è®¡ç®—: (p',t') * (t',) * (p',) * (p',) * scalar -> (t', p')
    
    # A_TT(p',t_fixed_val,t') -> (p', t')
    a_tt_term1 = At_torch[:, t_fixed_val, :]  # (p', t')
    # W^Ïƒ^T(t',p_fixed_val) -> (t',)
    w_sigma_t_p_fixed = W_sigma_t_torch[:, p_fixed_val]  # (t',)
    # A_PP(t_fixed_val,p_fixed_val,p') -> (p',)
    a_pp_term1 = As_torch[t_fixed_val, p_fixed_val, :]  # (p',)
    # W^Ïƒ^S(t_fixed_val,p') -> (p',)
    w_sigma_s_t_fixed = W_sigma_s_torch[t_fixed_val, :]  # (p',)
    
    # è®¡ç®—Term1: (p',t') * (t',) * (p',) * (p',) -> (t', p')
    # å…ˆå¤„ç†æ—¶é—´ç»´åº¦ï¼š(p',t') * (t',) -> (p',t')
    term1_pt_part = a_tt_term1 * w_sigma_t_p_fixed[None, :]  # (p', t')
    # å†å¤„ç†ç©ºé—´ç»´åº¦ï¼š(p',t') * (p',) * (p',) -> (p',t')
    term1_pt_part = term1_pt_part * (a_pp_term1[:, None] * w_sigma_s_t_fixed[:, None])  # (p', t')
    # è½¬ç½®ä¸º (t', p')
    term1_t_p = term1_pt_part.T * w1_scalar  # (t', p')
    
    # Term 2: I_TT(t,t') * A_PP(t,p,p') * W^Ïƒ^S(t,p') * w2
    # I_TT(t_fixed_val,t') = 1 only when t'=t_fixed_val
    # ç®€åŒ–ä¸º: delta(t', t_fixed_val) * A_PP(t_fixed_val,p_fixed_val,p') * W^Ïƒ^S(t_fixed_val,p') * w2
    term2_t_p = torch.zeros(t_max, p_max)
    term2_t_p[t_fixed_val, :] = a_pp_term1 * w_sigma_s_t_fixed * w2_scalar
    
    # Term 3: I_PP(p',p) * A_TT(p,t,t') * W^Ïƒ^T(t',p) * w3
    # I_PP(p', p_fixed_val) = 1 only when p'=p_fixed_val
    # ç®€åŒ–ä¸º: delta(p', p_fixed_val) * A_TT(p_fixed_val,t_fixed_val,t') * W^Ïƒ^T(t',p_fixed_val) * w3
    term3_t_p = torch.zeros(t_max, p_max)
    a_tt_term3 = At_torch[p_fixed_val, t_fixed_val, :]  # (t',) - A_TT(p_fixed_val,t_fixed_val,t')
    term3_t_p[:, p_fixed_val] = a_tt_term3 * w_sigma_t_p_fixed * w3_scalar
    
    K_t_prime_p_prime = term1_t_p + term2_t_p + term3_t_p
    
    # è¿”å›Kå¼ é‡å’Œéšæœºæ•°ç´¢å¼•
    fixed_indices = {
        'd_fixed_val': d_fixed_val,
        'd_prime_fixed_val': d_prime_fixed_val,
        't_fixed_val': t_fixed_val,
        'p_fixed_val': p_fixed_val,
        'd_fixed': d_fixed is not None,
        'd_prime_fixed': d_prime_fixed is not None,
        't_fixed': t_fixed is not None,
        'p_fixed': p_fixed is not None
    }
    
    return (K_t_prime_p_prime.numpy(), fixed_indices,
            term1_t_p.numpy(), term2_t_p.numpy(), term3_t_p.numpy())

def process_sample(sample_file, output_dir, global_seed=None, 
                  d_fixed=None, d_prime_fixed=None, t_fixed=None, p_fixed=None):
    """
    å¤„ç†å•ä¸ªæ ·æœ¬ï¼Œè®¡ç®—ç®€åŒ–çš„Kå¼ é‡
    
    Args:
        sample_file: æ ·æœ¬æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        global_seed: å…¨å±€éšæœºç§å­
        d_fixed: æŒ‡å®šçš„ç‰¹å¾ç»´åº¦ dï¼ŒNoneè¡¨ç¤ºéšæœºé€‰æ‹©
        d_prime_fixed: æŒ‡å®šçš„ç‰¹å¾ç»´åº¦ d'ï¼ŒNoneè¡¨ç¤ºéšæœºé€‰æ‹©
        t_fixed: æŒ‡å®šçš„æ—¶é—´ç´¢å¼• tï¼ŒNoneè¡¨ç¤ºéšæœºé€‰æ‹©
        p_fixed: æŒ‡å®šçš„ç©ºé—´ç´¢å¼• pï¼ŒNoneè¡¨ç¤ºéšæœºé€‰æ‹©
    """
    sample_name = os.path.basename(sample_file).replace('_weights.npz', '')
    print(f"Processing {sample_name}...")
    
    # åŠ è½½æƒé‡æ•°æ®
    data = np.load(sample_file)
    
    # å¤„ç†æ¯ä¸€å±‚
    K_t_prime_p_prime_layers = []
    fixed_indices_layers = []
    # ä¿å­˜ä¸‰ä¸ªé¡¹çš„åˆ—è¡¨ - K(t',p')
    term1_t_p_layers = []
    term2_t_p_layers = []
    term3_t_p_layers = []
    # ä¿å­˜1+2é¡¹çš„å’Œ
    term12_sum_t_p_layers = []
    
    for layer in range(6):
        print(f"  Computing simplified K tensors for layer {layer+1}...")
        
        # è·å–å½“å‰å±‚çš„æ•°æ®
        Wdd1 = data[f'layer_{layer}_Wdd1']
        Wdd2 = data[f'layer_{layer}_Wdd2']
        Wdd3 = data[f'layer_{layer}_Wdd3']
        W_sigma_t = data[f'layer_{layer}_W_sigma_t']
        W_sigma_s = data[f'layer_{layer}_W_sigma_s']
        At = data[f'layer_{layer}_At']
        As = data[f'layer_{layer}_As']
        
        # ä½¿ç”¨å…¨å±€éšæœºç§å­ï¼ˆæ‰€æœ‰å±‚ä½¿ç”¨ç›¸åŒç§å­ï¼‰
        random_seed = global_seed
        
        print(f"    Layer {layer+1} random seed: {random_seed}")
        
        # è®¡ç®—ç®€åŒ–çš„Kå¼ é‡
        result = compute_K_simplified(
            At, As, W_sigma_t, W_sigma_s, Wdd1, Wdd2, Wdd3, 
            random_seed=random_seed, d_fixed=d_fixed, d_prime_fixed=d_prime_fixed,
            t_fixed=t_fixed, p_fixed=p_fixed)
        
        K_t_prime_p_prime, fixed_indices = result[:2]
        term1_t_p, term2_t_p, term3_t_p = result[2:5]
        
        K_t_prime_p_prime_layers.append(K_t_prime_p_prime)
        fixed_indices_layers.append(fixed_indices)
        # ä¿å­˜K(t',p')çš„ä¸‰ä¸ªé¡¹
        term1_t_p_layers.append(term1_t_p)
        term2_t_p_layers.append(term2_t_p)
        term3_t_p_layers.append(term3_t_p)
        # è®¡ç®—å¹¶ä¿å­˜1+2é¡¹çš„å’Œ
        term12_sum_t_p = term1_t_p + term2_t_p
        term12_sum_t_p_layers.append(term12_sum_t_p)
        
        print(f"    Layer {layer+1}: K_t_prime_p_prime shape = {K_t_prime_p_prime.shape}")
        print(f"    Layer {layer+1}: K(t',p') terms shape = {term1_t_p.shape} each")
        print(f"    Layer {layer+1}: term1+term2 sum shape = {term12_sum_t_p.shape}")
    
    # ä¿å­˜ç»“æœ
    output_file = os.path.join(output_dir, f'{sample_name}_K_simplified.npz')
    save_dict = {}
    for i in range(6):
        save_dict[f'layer_{i}_K_t_prime_p_prime'] = K_t_prime_p_prime_layers[i]
        # ä¿å­˜K(t',p')è®¡ç®—å…¬å¼çš„ä¸‰ä¸ªé¡¹
        save_dict[f'layer_{i}_term1_t_p'] = term1_t_p_layers[i]
        save_dict[f'layer_{i}_term2_t_p'] = term2_t_p_layers[i]
        save_dict[f'layer_{i}_term3_t_p'] = term3_t_p_layers[i]
        # ä¿å­˜1+2é¡¹çš„å’Œ
        save_dict[f'layer_{i}_term12_sum_t_p'] = term12_sum_t_p_layers[i]
    
    np.savez(output_file, **save_dict)
    print(f"Saved simplified K tensors and individual terms to {output_file}")
    
    # è¿”å›å›ºå®šç´¢å¼•ä¾›ä¸»å‡½æ•°ä¿å­˜
    return fixed_indices_layers[0] if fixed_indices_layers else None

def parse_range_string(range_str, available_items):
    """
    è§£æèŒƒå›´å­—ç¬¦ä¸²ï¼Œæ”¯æŒæ ¼å¼ï¼š
    - "all"      -> æ‰€æœ‰å¯ç”¨é¡¹
    - "0"        -> [0]
    - "0,1,2"    -> [0,1,2]
    - "0-5"      -> [0,1,2,3,4,5]
    - "0-5,8"    -> [0,1,2,3,4,5,8]
    
    Args:
        range_str: èŒƒå›´å­—ç¬¦ä¸²
        available_items: å¯ç”¨é¡¹åˆ—è¡¨
        
    Returns:
        list: è§£æåçš„é¡¹åˆ—è¡¨
    """
    if range_str.lower() == 'all':
        return available_items
    
    result = []
    parts = range_str.split(',')
    
    for part in parts:
        part = part.strip()
        if '-' in part:
            start, end = map(int, part.split('-'))
            result.extend(range(start, end + 1))
        else:
            result.append(int(part))
    
    # è¿‡æ»¤æ‰ä¸åœ¨å¯ç”¨é¡¹ä¸­çš„å€¼
    result = [x for x in result if x in available_items]
    return sorted(list(set(result)))

def main():
    """ä¸»å‡½æ•° - è®¡ç®—ç®€åŒ–çš„Kå¼ é‡ - å›ºå®š(t,p,d,d')è®©(t',p')å˜åŒ–"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    print("Starting simplified K tensor calculation...")
    print("Computing K_t_prime_p_prime: (t', p') with fixed (t,p,d,d')")
    print("=" * 60)
    
    # å¤„ç†éšæœºç§å­
    global_seed = args.global_seed if args.global_seed != -1 else None
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if args.add_seed_suffix:
        if global_seed is not None:
            output_dir = f"{args.output_dir}_{global_seed}"
        else:
            output_dir = f"{args.output_dir}_random"
    else:
        output_dir = args.output_dir
    
    os.makedirs(output_dir, exist_ok=True)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("ğŸ“‹ å½“å‰é…ç½®:")
    print(f"  è¾“å…¥ç›®å½•: {args.input_dir}")
    print(f"  è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  å…¨å±€éšæœºç§å­: {global_seed}")
    print(f"  æ•°æ®é›†é€‰æ‹©: {args.datasets}")
    print(f"  æ ·æœ¬é€‰æ‹©: {args.samples}")
    print(f"  å›ºå®šç»´åº¦é…ç½®:")
    print(f"    d_fixed: {args.d_fixed}")
    print(f"    d'_fixed: {args.d_prime_fixed}")
    print(f"    t_fixed: {args.t_fixed}")
    print(f"    p_fixed: {args.p_fixed}")
    print()
    
    # éšæœºç§å­è¯´æ˜
    if global_seed is not None:
        print("ğŸ² ç§å­ç”Ÿæˆè§„åˆ™: æ‰€æœ‰æ ·æœ¬å’Œå±‚ä½¿ç”¨ç›¸åŒçš„å…¨å±€ç§å­")
    else:
        print("ğŸ² ç§å­ç”Ÿæˆè§„åˆ™: å®Œå…¨éšæœºï¼ˆæ¯æ¬¡è¿è¡Œç»“æœä¸åŒï¼‰")
    print()
    
    # è·å–æ‰€æœ‰æ•°æ®é›†ç›®å½•
    dataset_dirs = [d for d in os.listdir(args.input_dir) 
                   if os.path.isdir(os.path.join(args.input_dir, d)) and d.startswith('dataset_')]
    dataset_dirs.sort()
    
    if not dataset_dirs:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ•°æ®é›†ç›®å½•ï¼")
        return
    
    # è§£ææ•°æ®é›†èŒƒå›´
    available_dataset_ids = [int(d.split('_')[1]) for d in dataset_dirs]
    selected_dataset_ids = parse_range_string(args.datasets, available_dataset_ids)
    selected_dataset_dirs = [f'dataset_{id}' for id in selected_dataset_ids]
    
    print(f"ğŸ“ æ‰¾åˆ°æ•°æ®é›†: {[d.split('_')[1] for d in dataset_dirs]}")
    print(f"ğŸ“ å°†å¤„ç†æ•°æ®é›†: {[str(id) for id in selected_dataset_ids]}")
    print()
    
    for dataset_dir in selected_dataset_dirs:
        print(f"ğŸ”„ å¤„ç† {dataset_dir}...")
        dataset_input_path = os.path.join(args.input_dir, dataset_dir)
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºè¾“å‡ºç›®å½•
        dataset_output_dir = os.path.join(output_dir, dataset_dir)
        os.makedirs(dataset_output_dir, exist_ok=True)
        
        # è·å–è¯¥æ•°æ®é›†ä¸‹çš„æ‰€æœ‰æƒé‡æ–‡ä»¶
        weight_files = [f for f in os.listdir(dataset_input_path) if f.endswith('_weights.npz')]
        weight_files.sort()
        
        if not weight_files:
            print(f"  âš ï¸  {dataset_dir} ä¸­æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ï¼Œè·³è¿‡")
            continue
        
        # è§£ææ ·æœ¬èŒƒå›´
        available_sample_ids = [int(f.split('_')[1]) for f in weight_files 
                              if f.startswith('sample_') and f.endswith('_weights.npz')]
        selected_sample_ids = parse_range_string(args.samples, available_sample_ids)
        selected_weight_files = [f'sample_{id}_weights.npz' for id in selected_sample_ids]
        
        print(f"  ğŸ“„ æ‰¾åˆ°æ ·æœ¬æ–‡ä»¶: {len(weight_files)} ä¸ª")
        print(f"  ğŸ“„ å°†å¤„ç†æ ·æœ¬: {selected_sample_ids}")
        
        # ä¿å­˜éšæœºæ•°ï¼ˆåªéœ€è¦å¤„ç†ç¬¬ä¸€ä¸ªæ ·æœ¬æ¥è·å–éšæœºæ•°ï¼‰
        random_indices = None
        
        for weight_file in tqdm(selected_weight_files, desc=f"å¤„ç† {dataset_dir}"):
            if weight_file not in weight_files:
                print(f"  âš ï¸  æ ·æœ¬æ–‡ä»¶ {weight_file} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue
                
            weight_path = os.path.join(dataset_input_path, weight_file)
            sample_fixed_indices = process_sample(weight_path, dataset_output_dir, 
                         global_seed=global_seed,
                         d_fixed=args.d_fixed, d_prime_fixed=args.d_prime_fixed,
                         t_fixed=args.t_fixed, p_fixed=args.p_fixed)
            
            # åªä¿å­˜ç¬¬ä¸€ä¸ªæ ·æœ¬çš„å›ºå®šç´¢å¼•ï¼ˆæ‰€æœ‰æ ·æœ¬éƒ½ç›¸åŒï¼‰
            if random_indices is None:
                random_indices = sample_fixed_indices
        
        # ä¿å­˜å›ºå®šç´¢å¼•åˆ°datasetç›®å½•ä¸‹çš„rand.txt
        if random_indices is not None:
            random_file = os.path.join(dataset_output_dir, 'rand.txt')
            with open(random_file, 'w') as f:
                f.write(f"Dataset: {dataset_dir}\n")
                f.write(f"Global Seed: {global_seed}\n")
                f.write(f"Configuration:\n")
                f.write(f"  d_fixed: {args.d_fixed}\n")
                f.write(f"  d'_fixed: {args.d_prime_fixed}\n")
                f.write(f"  t_fixed: {args.t_fixed}\n")
                f.write(f"  p_fixed: {args.p_fixed}\n")
                f.write("-" * 50 + "\n")
                f.write(f"Actual fixed indices used (same for all samples and layers):\n")
                f.write(f"t_fixed_val: {random_indices['t_fixed_val']} {'(fixed)' if random_indices['t_fixed'] else '(random)'}\n")
                f.write(f"p_fixed_val: {random_indices['p_fixed_val']} {'(fixed)' if random_indices['p_fixed'] else '(random)'}\n")
                f.write(f"d_fixed_val: {random_indices['d_fixed_val']} {'(fixed)' if random_indices['d_fixed'] else '(random)'}\n")
                f.write(f"d_prime_fixed_val: {random_indices['d_prime_fixed_val']} {'(fixed)' if random_indices['d_prime_fixed'] else '(random)'}\n")
                f.write("\n")
                f.write("Note: (t',p') vary while (t,p,d,d') are fixed for all samples and layers.\n")
            
            print(f"  ğŸ’¾ å·²ä¿å­˜å›ºå®šç´¢å¼•åˆ° {random_file}")
    
    print()
    print("âœ… ç®€åŒ–Kå¼ é‡è®¡ç®—å®Œæˆï¼")
    print("ğŸ“Š ä¿å­˜çš„å¼ é‡ï¼ˆæ¯å±‚åŒ…å«ï¼‰:")
    print("  - K_t_prime_p_prime: (t', p') å¯¹åº”å›ºå®š(t,p,d,d')ä¸‹çš„æ ¸å‡½æ•°å€¼")
    print("  - term1_t_p, term2_t_p, term3_t_p: K(t',p')çš„ä¸‰ä¸ªåˆ†é¡¹")
    print("  - term12_sum_t_p: term1å’Œterm2çš„å’Œï¼ˆå‰ä¸¤é¡¹ä¹‹å’Œï¼‰")
    print("    å…¶ä¸­ K_t_prime_p_prime = term1_t_p + term2_t_p + term3_t_p")
    print("    å…¶ä¸­ term12_sum_t_p = term1_t_p + term2_t_p")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main()
